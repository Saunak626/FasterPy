Reading reference file from py_reference.jsonl
Reading model generated outputs from to_be_eval/test-qm-l-fp.jsonl
Running each program 4 times, skipping the first 1 runs, and getting the input-output pairs from codenet/public_test_cases
Read 752 rows from to_be_eval/test-qm-l-fp.jsonl
Unique inputs in reference: 993
Number of programs to evaluate: 752
Number of trials per program: 4
Number of trials to ignore: 1
Maximum time per run: 3
Input column: slow_code_col
Reference column: reference_code_col
Model generated column: model_generated_potentially_faster_code_col
inputs/outputs basepath: codenet/public_test_cases
--------------------------------------------------------------------------------
[Our measurement] input program (ms): 16.1080 ± 15.3088
[Our measurement] reference (output) program (ms): 3.4253 ± 3.8431
[Our measurement] model_generated_potentially_faster_code_col program (ms): 6.8918 ± 7.6134
----Metrics when improved--
Found 375 problems where the model_generated_potentially_faster_code_col program is faster than the reference program
[Our measurement] input program (ms): 12.6939 ± 13.2442
[Our measurement] reference (output) program (ms): 3.7602 ± 3.6710
[Our measurement] model_generated_potentially_faster_code_col program (ms): 1.5252 ± 2.2602
Number of cases where reference took longer by our measurement: 108
----- Additional Metrics -----
Valid samples (acc=1): 610
Optimized samples (faster than slow): 435
