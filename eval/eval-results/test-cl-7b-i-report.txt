Reading reference file from py_reference.jsonl
Reading model generated outputs from to_be_eval/test-cl-7-i.jsonl
Running each program 4 times, skipping the first 1 runs, and getting the input-output pairs from codenet/public_test_cases
Read 752 rows from to_be_eval/test-cl-7-i.jsonl
Unique inputs in reference: 993
Number of programs to evaluate: 752
Number of trials per program: 4
Number of trials to ignore: 1
Maximum time per run: 3
Input column: slow_code_col
Reference column: reference_code_col
Model generated column: model_generated_potentially_faster_code_col
inputs/outputs basepath: codenet/public_test_cases
--------------------------------------------------------------------------------
[Our measurement] input program (ms): 15.7177 ± 15.8141
[Our measurement] reference (output) program (ms): 3.6363 ± 3.8085
[Our measurement] model_generated_potentially_faster_code_col program (ms): 18.0034 ± 20.1298
----Metrics when improved--
Found 177 problems where the model_generated_potentially_faster_code_col program is faster than the reference program
[Our measurement] input program (ms): 1.3117 ± 1.2082
[Our measurement] reference (output) program (ms): 1.4124 ± 0.9662
[Our measurement] model_generated_potentially_faster_code_col program (ms): 0.9351 ± 0.7636
Number of cases where reference took longer by our measurement: 91
----- Additional Metrics -----
Valid samples (acc=1): 524
Optimized samples (faster than slow): 153
