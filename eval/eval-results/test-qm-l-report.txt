Reading reference file from py_reference.jsonl
Reading model generated outputs from to_be_eval/test-qm-l.jsonl
Running each program 4 times, skipping the first 1 runs, and getting the input-output pairs from codenet/public_test_cases
Read 752 rows from to_be_eval/test-qm-l.jsonl
Unique inputs in reference: 993
Number of programs to evaluate: 752
Number of trials per program: 4
Number of trials to ignore: 1
Maximum time per run: 3
Input column: slow_code_col
Reference column: reference_code_col
Model generated column: model_generated_potentially_faster_code_col
inputs/outputs basepath: codenet/public_test_cases
--------------------------------------------------------------------------------
[Our measurement] input program (ms): 15.9043 ± 14.4210
[Our measurement] reference (output) program (ms): 3.0367 ± 3.8552
[Our measurement] model_generated_potentially_faster_code_col program (ms): 7.0354 ± 7.0891
----Metrics when improved--
Found 331 problems where the model_generated_potentially_faster_code_col program is faster than the reference program
[Our measurement] input program (ms): 12.3787 ± 13.7863
[Our measurement] reference (output) program (ms): 3.0813 ± 3.6780
[Our measurement] model_generated_potentially_faster_code_col program (ms): 1.4954 ± 2.3141
Number of cases where reference took longer by our measurement: 106
----- Additional Metrics -----
Valid samples (acc=1): 585
Optimized samples (faster than slow): 376
